-*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kf-2OoH5BDNoMULk56SPX2DdYHDo-sWo
"""

!pip install -q flwr[simulation] torch torchvision matplotlib

pip install tensorboard

pip install tensorboardX

pip install PyQt5

pip install firebase-admin==6.1.0

# Commented out IPython magic to ensure Python compatibility.


from collections import OrderedDict
from typing import List, Tuple
import pandas as pd 
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import CIFAR10
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import matplotlib


import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
from tensorboardX import SummaryWriter

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F

from torch.utils.data import random_split
from torch.utils.data.dataloader import DataLoader

from torchvision.utils import make_grid
from torchvision import models as models 
from torchvision.datasets import ImageFolder
from torchvision import transforms
from torchvision.transforms import ToTensor
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Tuple
# %matplotlib inline
import flwr as fl
from flwr.common import Metrics

from ..utils.firebase.fetch import fetchFromFirebase
from ..utils.firebase.push import pushToFirebase

DEVICE = torch.device("cpu")  # Try "cuda" to train on GPU
print(
    f"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}"
)

CLASSES = (
    "covid19",
    "pneumonia",
    "normal"
    )

NUM_CLIENTS = 5

data_dir = '/content/drive/MyDrive/Covid-19 Image dataset/Covid19-dataset/train'
data_dir2 = '/content/drive/MyDrive/Covid-19 Image dataset/Covid19-dataset/test'

transformer = torchvision.transforms.Compose(
    [ # Applying Augmentation
        torchvision.transforms.Resize((88,74)),
        torchvision.transforms.RandomHorizontalFlip(p=0.5),
        torchvision.transforms.RandomVerticalFlip(p=0.5),
        torchvision.transforms.RandomRotation(40),
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Grayscale(num_output_channels=1),
        torchvision.transforms.Normalize(
            mean=[0.4914], std=[0.2023]
        ), #
    ]
)

trainset = torchvision.datasets.ImageFolder(data_dir, transform=transformer)
testset = torchvision.datasets.ImageFolder(data_dir2, transform=transformer)

BATCH_SIZE = 32


def load_datasets():
    # Download and transform CIFAR-10 (train and test)
    # transform = transforms.Compose(
    #     [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
    # )
    # trainset = CIFAR10("./dataset", train=True, download=True, transform=transform)
    # testset = CIFAR10("./dataset", train=False, download=True, transform=transform)
    # Split training set into 10 partitions to simulate the individual dataset
    partition_size = len(trainset) // NUM_CLIENTS
    lengths = [partition_size] * NUM_CLIENTS
    print(len(trainset))
    print()
    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))

    # Split each partition into train/val and create DataLoader
    trainloaders = []
    valloaders = []
    for ds in datasets:
        len_val = len(ds) // 10  # 10 % validation set
        len_train = len(ds) - len_val
        lengths = [len_train, len_val]
        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))
        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))
        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))
    testloader = DataLoader(testset, batch_size=BATCH_SIZE)
    return trainloaders, valloaders, testloader


trainloaders, valloaders, testloader = load_datasets()

images, labels = next(iter(trainloaders[0]))

# Reshape and convert images to a NumPy array
# matplotlib requires images with the shape (height, width, 3)
images = images.permute(0, 2, 3, 1).numpy()
# Denormalize
images = images / 2 + 0.5

# Create a figure and a grid of subplots
fig, axs = plt.subplots(4, 8, figsize=(12, 6))

# Loop over the images and plot them
for i, ax in enumerate(axs.flat):
    ax.imshow(images[i])
    ax.set_title(CLASSES[labels[i]])
    ax.axis("off")

# Show the plot
fig.tight_layout()
plt.show()

class Net(nn.Module):
    def __init__(self) -> None:
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5) 
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 15 * 19, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = x.view(-1, 1, 88, 74)
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 15 * 19)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# def train(net, trainloader, epochs: int, verbose=False):
#     """Train the network on the training set."""
#     criterion = torch.nn.CrossEntropyLoss()
#     optimizer = torch.optim.Adam(net.parameters())
#     net.train()
#     writer = SummaryWriter()
#     for epoch in range(epochs):
#         correct, total, epoch_loss = 0, 0, 0.0
#         running_loss = 0.0
#         for images, labels in trainloader:
#             images, labels = images.to(DEVICE), labels.to(DEVICE)
#             optimizer.zero_grad()
#             outputs = net(images)
#             loss = criterion(outputs, labels)
#             loss.backward()
#             optimizer.step()
#             # Metrics
#             epoch_loss += loss
#             total += labels.size(0)
#             correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()
#             running_loss += loss.item()
#             if epoch % 10 == 9:
#                 # Write the loss to Tensorboard
#                 writer.add_scalar('train/loss', running_loss / 100, epoch * len(trainloader) + i)
#                 running_loss = 0.0
#         epoch_loss /= len(trainloader.dataset)
#         epoch_acc = correct / total
#         writer.add_graph(net,images)
#         if verbose:
#             print(f"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}")
def train(net, trainloader, epochs: int, verbose=False):
    """Train the network on the training set."""
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(net.parameters())
    net.train()
    writer = SummaryWriter()
    global_step = 0
    for epoch in range(epochs):
        correct, total, epoch_loss = 0, 0, 0.0
        running_loss = 0.0
        i = 0  # Define the iterator variable
        for images, labels in trainloader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = net(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            # Metrics
            epoch_loss += loss
            total += labels.size(0)
            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()
            running_loss += loss.item()
            if i % 100 == 99:
                # Write the loss to Tensorboard
                writer.add_scalar('train/loss', running_loss / 100, global_step)
                running_loss = 0.0
            i += 1  # Increment the iterator variable
            global_step += 1
        epoch_loss /= len(trainloader.dataset)
        epoch_acc = correct / total
        writer.add_scalar('train/accuracy', epoch_acc, epoch)
        writer.add_scalar('train/loss', epoch_loss, epoch)
        writer.add_graph(net,images)
        if verbose:
            print(f"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}")


def test(net, testloader):
    """Evaluate the network on the entire test set."""
    criterion = torch.nn.CrossEntropyLoss()
    correct, total, loss = 0, 0, 0.0
    net.eval()
    with torch.no_grad():
        for images, labels in testloader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = net(images)
            loss += criterion(outputs, labels).item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    loss /= len(testloader.dataset)
    accuracy = correct / total
    return loss, accuracy
def plot_distance_from_baseline(baseline_model, client_models):
    """Plot the Euclidean distance between each client model and the baseline model."""
    # Compute the baseline model's weights
    baseline_weights = [param.detach().clone() for param in baseline_model.parameters()]

    # Compute the Euclidean distance between each client model and the baseline model
    distances = []
    for client_model in client_models:
        client_weights = [param.detach().clone() for param in client_model.parameters()]
        distance = sum([(client_weight - baseline_weight).norm().item() ** 2 for client_weight, baseline_weight in zip(client_weights, baseline_weights)]) ** 0.5
        distances.append(distance)

    # Plot the distances
    plt.plot(distances)
    plt.xlabel('Client ID')
    plt.ylabel('Distance from baseline model')
    plt.show()

trainloader = trainloaders[0]
valloader = valloaders[0]
net = Net().to(DEVICE)

for epoch in range(20):
    train(net, trainloader, 1)
    loss, accuracy = test(net, valloader)
    print(f"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}")

loss, accuracy = test(net, testloader)
print(f"Final test set performance:\n\tloss {loss}\n\taccuracy {accuracy}")

# !tensorboard --logdir='/content/runs/Mar29_01-22-30_2df1b0db0f52' --port=6007
!tensorboard --logdir {'/content/runs/'}  --host localhost

def get_parameters(net) -> List[np.ndarray]:
    return [val.cpu().numpy() for _, val in net.state_dict().items()]


def set_parameters(net, parameters: List[np.ndarray]):
    params_dict = zip(net.state_dict().keys(), parameters)
    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})
    net.load_state_dict(state_dict, strict=True)

import matplotlib.pyplot as plt


class FlowerClient(fl.client.NumPyClient):
    def __init__(self, net, trainloader, valloader):
        self.net = net
        self.trainloader = trainloader
        self.valloader = valloader
        self.distances = np.zeros((10, 1))
        self.iteration = 0
        self.distances_history = []

    def get_parameters(self, config):
        return get_parameters(self.net)

    def fit(self, parameters, config):
        set_parameters(self.net, parameters)
        train(self.net, self.trainloader, epochs=1)
        current_params = get_parameters(self.net)
        current_params=np.array(current_params,dtype=object)
        parameters=np.array(parameters,dtype=object)
        
        for i in range(10):
            distance = np.linalg.norm(current_params[i] - parameters[i]) 
            self.distances[i, 0] = distance
            
        self.iteration += 1
        self.distances_history.append(np.mean(self.distances))
        print(self.distances_history)
        new_distance_history = fetchFromFirebase('distance', 'distance_history')
        new_distance_history['distance_history'].append(self.distances_history[0])
        pushToFirebase(new_distance_history,'distance', 'distance_history',['distance_history'])      
        # AT this point I have both the numpy array and the list which is required to be stored
        

        return get_parameters(self.net), len(self.trainloader), {}

    def evaluate(self, parameters, config):
        set_parameters(self.net, parameters)
        loss, accuracy = test(self.net, self.valloader)
        return float(loss), len(self.valloader), {"accuracy": float(accuracy)}


# class FlowerClient(fl.client.NumPyClient):
#     def __init__(self, net, trainloader, valloader):
#         self.net = net
#         self.trainloader = trainloader
#         self.valloader = valloader
#         self.distances = np.zeros((10, 1))

#     def get_parameters(self, config):
#         return get_parameters(self.net)

#     def fit(self, parameters, config):
#         set_parameters(self.net, parameters)
#         train(self.net, self.trainloader, epochs=1)
#         current_params = get_parameters(self.net)
#         current_params=np.array(current_params,dtype=object)
#         parameters=np.array(parameters,dtype=object)
#         # distance = np.linalg.norm(current_params- parameters,axis=0)
#         # print(distance)
#         for i in range(10):
#             distance = np.linalg.norm(current_params[i] - parameters[i])
#             print(distance)
#             self.distances[i] = distance

#         return get_parameters(self.net), len(self.trainloader), {}

#     def evaluate(self, parameters, config):
#         set_parameters(self.net, parameters)
#         loss, accuracy = test(self.net, self.valloader)
#         return float(loss), len(self.valloader), {"accuracy": float(accuracy)}

def client_fn(cid: str) -> FlowerClient:
    """Create a Flower client representing a single organization."""

    # Load model
    net = Net().to(DEVICE)


    # Note: each client gets a different trainloader/valloader, so each client
    # will train and evaluate on their own unique data
    trainloader = trainloaders[int(cid)]
    valloader = valloaders[int(cid)]
    # Create a single Flower client representing a single organization
    client = FlowerClient(net, trainloader, valloader)
    
    return client

import time

# Create FedAvg strategy
strategy = fl.server.strategy.FedAvg(
    fraction_fit=1.0,  
    fraction_evaluate=0.5,  
    min_fit_clients=5,  
    min_evaluate_clients=3,  
    min_available_clients=5, 
)

# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)
client_resources = None
if DEVICE.type == "cuda":
    client_resources = {"num_gpus": 1}

# Start simulation
fl.simulation.start_simulation(
    client_fn=client_fn,
    num_clients=NUM_CLIENTS,
    config=fl.server.ServerConfig(num_rounds=5),
    strategy=strategy,
    client_resources=client_resources,
)
# time.sleep(10)


# baseline_model = clients[0].get_parameters()
# client_models = [client.get_parameters() for client in clients[1:]]
# plot_distance_from_baseline(baseline_model, client_models)