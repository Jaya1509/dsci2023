{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e8d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db913bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Convolution2D, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling1D\n",
    "from keras import backend as K\n",
    "from keras import backend\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import csv\n",
    "from itertools import repeat\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.stats import entropy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35196b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algoName='CNN'\n",
    "# activationFun='relu'\n",
    "# optimizerName='Adam'\n",
    "# def createDeepModel():\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     if(algoName=='CNN'):    \n",
    "#         model.add(Conv1D(filters=5, kernel_size=3, activation=activationFun,input_shape = (x_shape, 1))) # changed x_data.shape[1] to x_shape\n",
    "#         model.add(Dropout(0.1))\n",
    "#         model.add(MaxPooling1D(pool_size=3))\n",
    "        \n",
    "#         model.add(Conv1D(filters=5, kernel_size=3, activation=activationFun))\n",
    "#         model.add(Dropout(0.05))\n",
    "#         model.add(MaxPooling1D(pool_size=3))\n",
    "        \n",
    "#         model.add(Flatten())  # Uncommented this line\n",
    "#         model.add(Dense(x_shape, activation=activationFun))\n",
    "#         model.add(Dense(mean_shape, activation=activationFun))\n",
    "#         model.add(Dense(50, activation=activationFun))\n",
    "#         model.add(Dense(outputClasses, activation='sigmoid'))\n",
    "#         model.compile(loss='mean_squared_error', optimizer=optimizerName, metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "# deepModel=createDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61230cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accList, precList, recallList, f1List = [], [], [], []\n",
    "numOfClients=4\n",
    "numOfIterations=1\n",
    "deepModelAggWeights=[]\n",
    "firstClientFlag=True\n",
    "modelLocation='C:\\\\Users\\\\PRAKHAR\\\\Documents\\\\GitHub\\\\dsci2023\\\\saved_model\\\\'+\"final_model.h5\"\n",
    "# Load the global model from the .h5 file\n",
    "globalModel = load_model('final_model.h5')\n",
    "globalModelFinal = load_model('final_model.h5')\n",
    "def updateServerModel(clientModel, clientModelWeight) :\n",
    "    global firstClientFlag\n",
    "    for ind in range(len(clientModelWeight)):\n",
    "        if(firstClientFlag==True):\n",
    "            deepModelAggWeights.append(clientModelWeight[ind])   \n",
    "        else:\n",
    "            deepModelAggWeights[ind]=(deepModelAggWeights[ind]+clientModelWeight[ind])\n",
    "            \n",
    "def updateClientsModels():\n",
    "    global clientsModelList\n",
    "    clientsModelList.clear()\n",
    "    for clientID in range(numOfClients):\n",
    "        m = keras.models.clone_model(globalModel)\n",
    "        m.set_weights(globalModel.get_weights())\n",
    "        clientsModelList.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f6c29b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from keras.models import load_model\n",
    "\n",
    "start_time = time.time()\n",
    "process = psutil.Process(os.getpid())\n",
    "arr = []\n",
    "cols, rows = numOfClients, numOfIterations\n",
    "\n",
    "def flatten_weights(weights):\n",
    "    flattened_weights = []\n",
    "    for weight in weights:\n",
    "        flattened_weights.extend(weight.flatten())\n",
    "    return np.array(flattened_weights)\n",
    "\n",
    "# def compute_euclidean_distance(weights1, weights2):\n",
    "#     return distance.euclidean(weights1, weights2)\n",
    "# def compute_hausdorff_distance(set1, set2):\n",
    "#     max_distance = 0.0\n",
    "#     for point1 in set1:\n",
    "#         min_distance = float('inf')\n",
    "#         for point2 in set2:\n",
    "#             distance = compute_euclidean_distance(point1, point2)  # Replace 'some_distance_function' with your distance function d(a, b)\n",
    "#             min_distance = min(min_distance, distance)\n",
    "#         max_distance = max(max_distance, min_distance)\n",
    "#     return max_distance\n",
    "def compute_hausdorff_distance(set1, set2):\n",
    "    # Reshape the sets to have a shape of (N, 1, D) for broadcasting\n",
    "    set1 = set1.reshape(-1, 1, set1.shape[-1])\n",
    "    set2 = set2.reshape(1, -1, set2.shape[-1])\n",
    "    \n",
    "    # Compute the pairwise Euclidean distances between points in set1 and set2\n",
    "    distances = np.linalg.norm(set1 - set2, axis=-1)\n",
    "    # Find the maximum distance from set1 to set2 and vice versa\n",
    "    max_to_set2 = np.max(np.min(distances, axis=1))\n",
    "    max_to_set1 = np.max(np.min(distances, axis=0))\n",
    "    # Return the Hausdorff distance\n",
    "    return max(max_to_set1, max_to_set2)\n",
    "# Function to calculate the cosine similarity between two vectors\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "# Function to calculate the cosine difference between two vectors\n",
    "def cosine_difference(a, b):\n",
    "    return 1 - cosine_similarity(a, b)\n",
    "# Get the weights of the global model\n",
    "global_weights = flatten_weights(globalModel.get_weights())\n",
    "print(len(global_weights))\n",
    "\n",
    "# Load client models from .h5 files and store them in a list\n",
    "clientsModelList = []\n",
    "for clientID in range(numOfClients):\n",
    "    client_model = load_model(f\"client_model_{clientID}.h5\")\n",
    "    clientsModelList.append(client_model)\n",
    "print(len(clientsModelList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ff1d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "clientID 0\n",
      "[-0.2906119   0.50184655 -0.53207994 ...  0.09069712  0.03928225\n",
      " -0.03707767]\n",
      "clientID 1\n",
      "[-0.395617    0.48739505 -0.48584825 ...  0.15840667 -0.07099604\n",
      "  0.07232244]\n",
      "clientID 2\n",
      "[-0.37091103  0.53774303 -0.5352819  ...  0.1641018  -0.05915951\n",
      "  0.06118244]\n",
      "clientID 3\n",
      "[-0.37881097  0.5400526  -0.5193805  ...  0.16242798 -0.10011385\n",
      "  0.10700398]\n",
      "12\n",
      "12\n",
      "[-0.35898772  0.51675934 -0.51814765 ...  0.14390838 -0.04774679\n",
      "  0.0508578 ]\n",
      "Server's model updated\n",
      "Saving model . . .\n"
     ]
    }
   ],
   "source": [
    "for iterationNo in range(1,numOfIterations+1):\n",
    "    print(\"Iteration\",iterationNo)\n",
    "#     dis = []\n",
    "    for clientID in range(numOfClients):\n",
    "        print(\"clientID\",clientID)\n",
    "        clientWeight=clientsModelList[clientID].get_weights() \n",
    "        # Compute and print Euclidean distance\n",
    "        client_weights = flatten_weights(clientWeight)\n",
    "        print(client_weights)\n",
    "#         hausdorff_distance = compute_hausdorff_distance(global_weights, client_weights)\n",
    "#         print(f\"Hausdorff distance between global model and client {clientID}: {hausdorff_distance}\")\n",
    "#         dis.append(hausdorff_distance)\n",
    "        updateServerModel(clientsModelList[clientID], clientWeight)\n",
    "        firstClientFlag=False\n",
    "#     arr.append(dis)\n",
    "    #Average all clients model\n",
    "    print(len(deepModelAggWeights))\n",
    "    for ind in range(len(deepModelAggWeights)):\n",
    "        deepModelAggWeights[ind]/=numOfClients\n",
    "#         print(deepModelAggWeights[ind])\n",
    "    dw_last=globalModel.get_weights()\n",
    "    \n",
    "    print(len(dw_last))\n",
    "    for ind in range(len(deepModelAggWeights)): \n",
    "        dw_last[ind]=deepModelAggWeights[ind]\n",
    "    \n",
    "    #Update server's model\n",
    "    globalModel.set_weights(dw_last)\n",
    "    dw_last = deepModelAggWeights.copy()\n",
    "    globalModel.set_weights(dw_last)\n",
    "    print(flatten_weights(globalModel.get_weights()))\n",
    "    print(\"Server's model updated\")\n",
    "    print(\"Saving model . . .\")\n",
    "    globalModel.save(\"final_model.h5\")\n",
    "    # Servers model is updated, now it can be used again by the clients\n",
    "#     updateClientsModels()\n",
    "    firstClientFlag=True\n",
    "    deepModelAggWeights.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f663508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156\n",
      "Client 0 Hausdorff Distance: 11.46939754486084, Cosine Difference: nan\n",
      "Client 1 Hausdorff Distance: 11.394619941711426, Cosine Difference: nan\n",
      "Client 2 Hausdorff Distance: 11.244811058044434, Cosine Difference: nan\n",
      "Client 3 Hausdorff Distance: 11.412675857543945, Cosine Difference: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAKHAR\\AppData\\Local\\Temp\\ipykernel_17536\\864390595.py:50: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  return dot_product / (norm_a * norm_b)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate the difference between the updated global model and globalModelFinal\n",
    "global_model_difference = []\n",
    "global_model_final_weights = flatten_weights(globalModelFinal.get_weights())\n",
    "global_model_weights = flatten_weights(globalModel.get_weights())\n",
    "\n",
    "for i in range(len(global_model_final_weights)):\n",
    "    diff = global_model_weights[i] - global_model_final_weights[i]\n",
    "    global_model_difference.append(diff)\n",
    "global_model_difference = flatten_weights(global_model_difference)\n",
    "\n",
    "# Step 2: Compute the Hausdorff distance between global_model_difference and each client model\n",
    "hausdorff_distances = []\n",
    "cosine_differences = []\n",
    "for clientID in range(numOfClients):\n",
    "    client_weights = flatten_weights(clientsModelList[clientID].get_weights())\n",
    "    distance = compute_hausdorff_distance(global_model_difference, client_weights)\n",
    "    hausdorff_distances.append(distance)\n",
    "    cosine_diff = cosine_difference(global_model_difference, client_weights)\n",
    "    cosine_differences.append(cosine_diff)\n",
    "print(len(client_weights))\n",
    "# Print the computed Hausdorff distances\n",
    "for clientID, (distance, cosine_diff) in enumerate(zip(hausdorff_distances, cosine_differences)):\n",
    "    print(f\"Client {clientID} Hausdorff Distance: {distance}, Cosine Difference: {cosine_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac424569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"sequential\" with a weight list of length 2156, but the layer was expecting 12 weights. Provided weights: [-0.35103885  0.50277019 -0.50672483 ...  0.130446...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     agg_weights[ind] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (numOfClients \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# numOfClients - 1, as we excluded one client\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Update server's model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mglobalModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflatten_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m globalModel\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1802\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1799\u001b[0m         expected_num_weights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expected_num_weights \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(weights):\n\u001b[1;32m-> 1802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1803\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou called `set_weights(weights)` on layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1804\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a weight list of length \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, but the layer was \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1805\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpecting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m weights. Provided weights: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1806\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   1807\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   1808\u001b[0m             \u001b[38;5;28mlen\u001b[39m(weights),\n\u001b[0;32m   1809\u001b[0m             expected_num_weights,\n\u001b[0;32m   1810\u001b[0m             \u001b[38;5;28mstr\u001b[39m(weights)[:\u001b[38;5;241m50\u001b[39m],\n\u001b[0;32m   1811\u001b[0m         )\n\u001b[0;32m   1812\u001b[0m     )\n\u001b[0;32m   1814\u001b[0m weight_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1815\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"sequential\" with a weight list of length 2156, but the layer was expecting 12 weights. Provided weights: [-0.35103885  0.50277019 -0.50672483 ...  0.130446..."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52415404",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_weights = flatten_weights(globalModel.get_weights())\n",
    "print(global_weights)\n",
    "global_final_weights = flatten_weights(globalModelFinal.get_weights())\n",
    "print(global_final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef349b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
